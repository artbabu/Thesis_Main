\contentsline {chapter}{\numberline {1}Introduction}{6}
\contentsline {section}{\numberline {1.1}Natural Language Semantics}{7}
\contentsline {section}{\numberline {1.2}Computational Semantics}{8}
\contentsline {section}{\numberline {1.3}Project Overview}{9}
\contentsline {chapter}{\numberline {2}Background}{11}
\contentsline {section}{\numberline {2.1}Semantic Textual Similarity (STS)}{11}
\contentsline {subsection}{\numberline {2.1.1}STS Applications}{13}
\contentsline {subsection}{\numberline {2.1.2}Data for STS}{14}
\contentsline {section}{\numberline {2.2}Brief History of Meaning Representation}{15}
\contentsline {section}{\numberline {2.3}Machine Learning models}{17}
\contentsline {subsection}{\numberline {2.3.1}Traditional ML models}{18}
\contentsline {subsection}{\numberline {2.3.2}Neural Networks}{21}
\contentsline {section}{\numberline {2.4}Word Vector Representation}{24}
\contentsline {section}{\numberline {2.5}Sentence Representation Model}{27}
\contentsline {chapter}{\numberline {3}Related Work}{29}
\contentsline {section}{\numberline {3.1}Traditional Machine Learning Models}{30}
\contentsline {section}{\numberline {3.2}Neural Models}{31}
\contentsline {chapter}{\numberline {4}Modeling Sentence Encoders}{35}
\contentsline {section}{\numberline {4.1}Ensemble Model}{38}
\contentsline {subsection}{\numberline {4.1.1}Features}{39}
\contentsline {subsection}{\numberline {4.1.2}Learning Models}{41}
\contentsline {section}{\numberline {4.2}Convoutional Neural Network}{42}
\contentsline {subsection}{\numberline {4.2.1}Sentence Model using CNN}{42}
\contentsline {subsection}{\numberline {4.2.2}Similarity Measure using FCNN}{45}
\contentsline {section}{\numberline {4.3}Recurrent Neural Network}{45}
\contentsline {subsection}{\numberline {4.3.1}Bi-LSTM with max pooling}{45}
\contentsline {subsubsection}{Semantic Difference Matrix}{48}
\contentsline {subsubsection}{Textual Entailment Classifier}{48}
\contentsline {section}{\numberline {4.4}Summary}{48}
\contentsline {chapter}{\numberline {5}Experiments}{50}
\contentsline {section}{\numberline {5.1}Encoder Architectures - Performance}{53}
\contentsline {subsection}{\numberline {5.1.1}Experiment Setup}{53}
\contentsline {subsection}{\numberline {5.1.2}Analysis}{53}
\contentsline {section}{\numberline {5.2}Hyper-parameter Tuning}{55}
\contentsline {subsection}{\numberline {5.2.1}Experiment Setup}{55}
\contentsline {subsection}{\numberline {5.2.2}Analysis}{56}
\contentsline {section}{\numberline {5.3}Input features for Traditional MLT}{57}
\contentsline {section}{\numberline {5.4}Transfer Learning}{58}
\contentsline {chapter}{\numberline {6}Conclusion}{60}
