\relax 
\providecommand\tcolorbox@label[2]{}
\citation{jurafsky2014speech}
\citation{jurafsky2014speech}
\citation{tian2017ecnu}
\citation{severyn2015learning}
\citation{shao2017hcti}
\citation{SeqMod2018Andrew}
\citation{conneau2017supervised}
\citation{agirre2016semeval}
\citation{jurafsky2014speech}
\citation{jurafsky2014speech}
\citation{jurafsky2014speech}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{6}}
\citation{harris1970distributional}
\citation{firth1957synopsis}
\citation{jurafsky2014speech}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Natural Language Semantics}{7}}
\newlabel{nlp_sem}{{1.1}{7}}
\citation{jurafsky2014speech}
\citation{pedersen2004wordnet}
\citation{salton1971smart,deerwester1989computer}
\citation{bengio2003neural,collobert2008unified,collobert2011natural,mikolov2011extensions}
\citation{mikolov2014word2vec,pennington2014glove}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Computational Semantics}{8}}
\newlabel{com_sem}{{1.2}{8}}
\citation{luong2015effective}
\citation{socher2011semi}
\citation{wen2015semantically}
\citation{kiros2015skip,conneau2017supervised,shao2017hcti}
\citation{conneau2017supervised}
\citation{agirre2012semeval}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Project Overview}{9}}
\newlabel{proj_overview}{{1.3}{9}}
\citation{cer2017semeval}
\citation{agirre2012semeval}
\citation{agirre2012semeval}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{background}{{2}{11}}
\newlabel{history}{{2}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Semantic Textual Similarity (STS)}{11}}
\newlabel{sts}{{2.1}{11}}
\citation{agirre2016semeval}
\citation{agirre2016semeval}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Degree for semantic relatedness (similarity score) \citep  {agirre2016semeval}\relax }}{12}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{STS score}{{2.1}{12}}
\citation{jurafsky2014speech}
\citation{jurafsky2014speech}
\citation{agirre2016semeval}
\citation{agirre2016semeval}
\citation{agirre2015semeval}
\citation{agirre2015semeval}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Recognizing Textual Entailment (Classification Label) \citep  {jurafsky2014speech}\relax }}{13}}
\newlabel{RTE class}{{2.2}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}STS Applications}{13}}
\newlabel{sts_app}{{2.1.1}{13}}
\citation{bowman2015large}
\citation{marelli2014semeval}
\citation{marelli2014semeval}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Data for STS}{14}}
\citation{bowman2015large}
\citation{salton1971smart}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Brief History of Meaning Representation}{15}}
\newlabel{history}{{2.2}{15}}
\citation{jurafsky2014speech}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces  Term-Document Matrix\relax }}{16}}
\newlabel{doc-word}{{2.1}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Term-Context Matrix\relax }}{16}}
\newlabel{word-word}{{2.2}{16}}
\citation{jurafsky2014speech}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Machine Learning models}{17}}
\newlabel{ml_model}{{2.3}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces A simple Decision Tree\relax }}{18}}
\newlabel{tree}{{2.3}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Traditional ML models}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Random Forest\relax }}{19}}
\newlabel{rf}{{2.4}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Neural Networks}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces A simple neuron\relax }}{22}}
\newlabel{neuron}{{2.5}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Neural Network\relax }}{23}}
\newlabel{net}{{2.6}{23}}
\citation{brown1992practical}
\citation{blei2003latent}
\citation{bengio2003neural}
\citation{collobert2008unified}
\citation{mikolov2014word2vec}
\citation{kiros2015skip}
\citation{jurafsky2014speech}
\citation{jurafsky2014speech}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Word Vector Representation}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Training samples for skip-gram - Words pairs from raw corpus\relax }}{26}}
\newlabel{train_sam}{{2.7}{26}}
\newlabel{eq1}{{2.10}{26}}
\citation{mikolov2014word2vec}
\citation{jurafsky2014speech}
\citation{jurafsky2014speech}
\citation{conneau2017supervised}
\citation{kiros2015skip}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Context and Word matrices \citep  {jurafsky2014speech}\relax }}{27}}
\newlabel{C_W_matrics}{{2.8}{27}}
\newlabel{eq2}{{2.11}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Skip-gram Model \citep  {jurafsky2014speech}\relax }}{28}}
\newlabel{skipgram}{{2.9}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Sentence Representation Model}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Summary}{29}}
\citation{conneau2017supervised}
\citation{conneau2017supervised}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Related Work}{30}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{related_work}{{3}{30}}
\citation{han2013umbc_ebiquity}
\citation{han2013umbc_ebiquity}
\citation{agirre2015semeval}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Traditional Machine Learning Models}{31}}
\newlabel{ml_models_rw}{{3.1}{31}}
\citation{tian2017ecnu}
\citation{cer2017semeval}
\citation{kiros2015skip}
\citation{mikolov2014word2vec}
\citation{cho2014learning}
\citation{marelli2014semeval}
\citation{tai2015improved}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Neural Models}{33}}
\newlabel{nu_models_rw}{{3.2}{33}}
\citation{shao2017hcti}
\citation{pennington2014glove}
\citation{pagliardini2017unsupervised}
\citation{mikolov2014word2vec}
\citation{conneau2017supervised}
\citation{kiros2015skip}
\citation{hill2016learning}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Summary}{35}}
\citation{conneau2017supervised}
\citation{shao2017hcti}
\citation{conneau2017supervised}
\citation{cer2017semeval}
\citation{conneau2017supervised}
\citation{bowman2015large}
\citation{marelli2014semeval}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Proposed Work}{37}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{proposed_work}{{4}{37}}
\citation{tian2017ecnu}
\citation{tian2017ecnu}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Ensemble Model}{39}}
\newlabel{ensemble}{{4.1}{39}}
\citation{tian2017ecnu}
\citation{tian2017ecnu}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Features}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Ensemble Model \citep  {tian2017ecnu}\relax }}{41}}
\newlabel{ensemble}{{4.1}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Objective Function}{43}}
\citation{shao2017hcti}
\citation{pennington2014glove}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Convoutional Neural Network}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Sentence Model using CNN}{44}}
\citation{severyn2015learning}
\citation{severyn2015learning}
\newlabel{CNN_1}{{\caption@xref {CNN_1}{ on input line 604}}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces CNN Sentence Model \cite  {severyn2015learning}\relax }}{45}}
\citation{shao2017hcti}
\citation{shao2017hcti}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Hyperparameters for FCNN \cite  {shao2017hcti}\relax }}{46}}
\newlabel{params}{{4.3}{46}}
\citation{conneau2017supervised}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Similarity Measure using FCNN}{47}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Recurrent Neural Network}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Bi-LSTM with max pooling}{47}}
\citation{SeqMod2018Andrew}
\citation{SeqMod2018Andrew}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces A Single LSTM cell \citep  {SeqMod2018Andrew}\relax }}{48}}
\newlabel{lstm}{{4.4}{48}}
\citation{conneau2017supervised}
\citation{conneau2017supervised}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces A Bi-LSTM Network \citep  {conneau2017supervised}\relax }}{49}}
\newlabel{bilstm}{{4.5}{49}}
\@writefile{toc}{\contentsline {subsubsection}{Semantic Difference Matrix}{50}}
\@writefile{toc}{\contentsline {subsubsection}{Textual Entailment Classifier}{50}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Summary}{50}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experiments and Results}{52}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{results}{{5}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Evaluation metric}{53}}
\newlabel{eval}{{5.1}{53}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Experiment Setup}{54}}
\newlabel{exp_setup}{{5.2}{54}}
\citation{bowman2015large}
\citation{marelli2014semeval}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Ensemble Model - Parameter Setup\relax }}{55}}
\newlabel{en-setup}{{5.1}{55}}
\citation{bird2004nltk}
\citation{manning2014stanford}
\citation{cer2017semeval}
\citation{bowman2015large}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Encoder Architectures - Performance}{57}}
\newlabel{performance}{{5.3}{57}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Analysis}{57}}
\citation{zhao2015self}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces  Peformance of Classical ML models\relax }}{58}}
\newlabel{Ml_perf}{{5.2}{58}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Performance of Neural Model in RTE and Sentence Relatednes Task\relax }}{58}}
\newlabel{neu_perf}{{5.3}{58}}
\citation{conneau2017supervised}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Hyper-parameter Tuning}{59}}
\newlabel{parameter-tune}{{5.4}{59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Analysis}{59}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Learning rate - optimizers\relax }}{60}}
\newlabel{lr-opt}{{5.4}{60}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Sentence Representation Dimension\relax }}{61}}
\newlabel{sent_dim}{{5.5}{61}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Input features for Traditional ML}{61}}
\newlabel{fests}{{5.5}{61}}
\citation{conneau2017supervised}
\citation{cer2017semeval}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces Performance of the Ensemble Model with different Input features on RTE task\relax }}{62}}
\newlabel{ensemblefeatures}{{5.6}{62}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Transfer Learning}{63}}
\newlabel{TL}{{5.6}{63}}
\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces Transfer Learning\relax }}{63}}
\newlabel{transfer}{{5.7}{63}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Summary}{64}}
\citation{conneau2017supervised}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{65}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{apalike}
\bibdata{sample}
\bibcite{agirre2015semeval}{{1}{2015}{{Agirre et~al.}}{{}}}
\bibcite{agirre2016semeval}{{2}{2016}{{Agirre et~al.}}{{}}}
\bibcite{agirre2012semeval}{{3}{2012}{{Agirre et~al.}}{{}}}
\bibcite{bengio2003neural}{{4}{2003}{{Bengio et~al.}}{{}}}
\bibcite{bird2004nltk}{{5}{2004}{{Bird and Loper}}{{}}}
\bibcite{blei2003latent}{{6}{2003}{{Blei et~al.}}{{}}}
\bibcite{bowman2015large}{{7}{2015}{{Bowman et~al.}}{{}}}
\bibcite{brown1992practical}{{8}{1992}{{Brown and Huntley}}{{}}}
\bibcite{cer2017semeval}{{9}{2017}{{Cer et~al.}}{{}}}
\bibcite{cho2014learning}{{10}{2014}{{Cho et~al.}}{{}}}
\bibcite{collobert2008unified}{{11}{2008}{{Collobert and Weston}}{{}}}
\bibcite{collobert2011natural}{{12}{2011}{{Collobert et~al.}}{{}}}
\bibcite{conneau2017supervised}{{13}{2017}{{Conneau et~al.}}{{}}}
\bibcite{deerwester1989computer}{{14}{1989}{{Deerwester et~al.}}{{}}}
\bibcite{firth1957synopsis}{{15}{1957}{{Firth}}{{}}}
\bibcite{han2013umbc_ebiquity}{{16}{2013}{{Han et~al.}}{{}}}
\bibcite{harris1970distributional}{{17}{1954}{{Harris}}{{}}}
\bibcite{hill2016learning}{{18}{2016}{{Hill et~al.}}{{}}}
\bibcite{jurafsky2014speech}{{19}{2014}{{Jurafsky and Martin}}{{}}}
\bibcite{kiros2015skip}{{20}{2015}{{Kiros et~al.}}{{}}}
\bibcite{luong2015effective}{{21}{2015}{{Luong et~al.}}{{}}}
\bibcite{manning2014stanford}{{22}{2014}{{Manning et~al.}}{{}}}
\bibcite{marelli2014semeval}{{23}{2014}{{Marelli et~al.}}{{}}}
\bibcite{mikolov2011extensions}{{24}{2011}{{Mikolov et~al.}}{{}}}
\bibcite{mikolov2014word2vec}{{25}{2013}{{Mikolov et~al.}}{{}}}
\bibcite{SeqMod2018Andrew}{{26}{2018}{{Ng}}{{}}}
\bibcite{pagliardini2017unsupervised}{{27}{2017}{{Pagliardini et~al.}}{{}}}
\bibcite{pedersen2004wordnet}{{28}{2004}{{Pedersen et~al.}}{{}}}
\bibcite{pennington2014glove}{{29}{2014}{{Pennington et~al.}}{{}}}
\bibcite{salton1971smart}{{30}{1971}{{Salton}}{{}}}
\bibcite{severyn2015learning}{{31}{2015}{{Severyn and Moschitti}}{{}}}
\bibcite{shao2017hcti}{{32}{2017}{{Shao}}{{}}}
\bibcite{socher2011semi}{{33}{2011}{{Socher et~al.}}{{}}}
\bibcite{tai2015improved}{{34}{2015}{{Tai et~al.}}{{}}}
\bibcite{tian2017ecnu}{{35}{2017}{{Tian et~al.}}{{}}}
\bibcite{wen2015semantically}{{36}{2015}{{Wen et~al.}}{{}}}
\bibcite{zhao2015self}{{37}{2015}{{Zhao et~al.}}{{}}}
